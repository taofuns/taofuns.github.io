<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>taofuns</title><description>The time I wasted, and the funs I got</description><link>https://taofuns.github.io</link><language>en</language><lastBuildDate>Mon, 7 Apr 2025 23:15:14 +0800</lastBuildDate><pubDate>Mon, 7 Apr 2025 23:15:14 +0800</pubDate><ttl>250</ttl><atom:link href="https://taofuns.github.io/feed.rss" rel="self" type="application/rss+xml"/><item><guid isPermaLink="true">https://taofuns.github.io/posts/Brief%20discussion%20on%20human-computer%20interaction</guid><title>Brief discussion on human-computer interaction</title><description></description><link>https://taofuns.github.io/posts/Brief%20discussion%20on%20human-computer%20interaction</link><pubDate>Wed, 22 May 2024 12:30:17 +0800</pubDate><content:encoded><![CDATA[<p>#Fn/Post #Domain/XR #CS/HCI</p><p>💡 为什么都 2022 年了，我们还在用键盘和鼠标进行人机交互？</p><p><strong>人机交互（Human Computer Interaction）</strong> 在历史上有两次伟大的革命。第一次是在 1983 年，由键盘和鼠标所定义 GUI 交互，这带来了消费级计算机的普及，很大程度上实现了比尔盖茨曾经的愿景：每个人都有一台 PC。第二次是在 2007 年，乔布斯带来了支持多点触控的 iPhone，由触摸和手势组成的屏幕直接交互引领了席卷全球的移动互联网浪潮，如今每个人已经远不止拥有一台智能设备，无处不在的计算设备重新定义了我们的生活。</p><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141237380.png" alt="Untitled"/><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141238513.png" alt="Untitled"/><p>从键盘鼠标到触摸手势，让人与计算机之间的距离不断缩短，更好的易用性带来更大范围的普及。但是环顾四周，我们的生活仍然离不开键盘和鼠标，特别是在与工作相关的生产力场景。即使是触摸屏时代的领跑产品 iPad，也在 2020 年的更新中配齐了键盘和触摸板。</p><p>当然，诚如 iPad Pro 在发布时的广告词所述“<em>你的下一台电脑何必是电脑</em>”，不禁让我们思考未来的人机交互形态。如今，人工智能、虚拟现实、增强现实等新技术纷至沓来，各种新形态的计算设备也出现在我们的日常生活中，<strong>那么什么又算是人机交互的第三次革命呢？</strong></p><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141238726.png" alt="Untitled"/><h2>一、人机交互简史</h2><p>在 ENIAC 时代，计算机是笨重且复杂的，世界上没有多少人能与这样的设备交互，直到上世纪 70 年代消费级计算机的兴起，键盘作为主要的输入设备与计算机交互才改善了这一局面。那个时代是命令行的天下，人类通过键盘输入指令，计算机响应指令。</p><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141238841.png" alt="Untitled"/><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141238956.png" alt="Untitled"/><p>然而这仍然太过复杂，记忆一连串的命令就让人头皮发麻。后来施乐公司发明了鼠标，乔布斯认为这是可以改变人机交互的技术，也借由苹果和微软公司的推介让 <strong>图形用户界面</strong>（GUI）走上历史舞台，一举将人机交互从一维世界带到二维世界。</p><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141238424.png" alt="Untitled"/><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141238544.png" alt="Untitled"/><p>在图形用户界面的背后是 <strong>桌面比喻</strong>（Desktop metaphor）和 <strong>纸本范式</strong>（paper paradigm）的设计思想。它将电脑比喻成一个桌面，电脑里的各个应用就是桌面上的工具，而文件是一张张纸，可以放入文件夹里。这一设计思想非常符合人类的心智模型，时至今日仍然在影响交互界面的设计。</p><p>对于熟练计算机操作的人，从命令行到图形用户界面并不意味着效率的增加，甚至是下降，但是图形用户界面以其友好性赢得了更广泛的用户群体，符合直觉的简单成为了人机交互的核心准则，这也为后来智能手机的普及埋下了伏笔。</p><p>时间来到 2007 年，乔布斯带来了支持多点触控的 iPhone，用手指直接操控手机这一更符合人类直觉的人机交互方案改变了世界，点击、拖动、捏合这些操作现在看起来习以为常，但在当时却是惊为天人。</p><blockquote><p>系统的复杂性的总量是一个恒量，把系统的一部分变得简单，那么剩下的部分就会变得更加复杂 ——特斯勒的复杂守恒定律</p></blockquote><p>触摸与手势这样简单的交互方式背后是复杂工程设计，不仅仅是硬件的支持，还需要软件的协同。举个简单的例子，最初的 iPhone 屏幕尺寸远不如现在，在小小的触摸屏上使用虚拟键盘进行输入的时候免不了误触，为了解决这个问题，苹果创新性地根据用户输入的内容预测后续的字符，从而改变响应字符触摸热区的大小，极大改善了用户体验。</p><p>回顾人机交互史上的两次革命，我们不难发现新的革命性的人机交互方案的出现总是为了解决一些人机交互的问题，键盘鼠标的出现解决了计算设备的易用性问题，而触摸手势的出现解决了计算设备的便携性问题。沿着这一思路，我们可以从当下的人机交互问题出发，约莫窥见未来的人机交互演进。</p><h2>二、新的交互方式</h2><p>苹果公司一直是世界范围内的人机交互引领者，从苹果各产品的更新中，我们可以看到近些年人机交互的演进。在 iPhone4s 上我们看到了 Siri 与其背后的 <strong>语音交互</strong>，在 iPhone5s 上我们看到了 TouchID 与其背后的 <strong>生物识别</strong>，在 iPhone6s 上我们看到了 3D Touch 将屏幕触控从二维扩展到三维（虽然这项技术在 iPhone 上后来被 Haptic Touch 所取代，但仍然应用于 Mac 的触摸板），在 iPhoneX 上我们看到了全面屏、FaceID、ARKit，在 iPhone、Mac、Homepod 之间我们看到了接力（Handoff）和隔空播放（AirPlay）这样的 <strong>设备互联</strong>。</p><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141238274.png" alt="Untitled"/><p>除了渐进式的演进，我们也可以看到像 Meta 这样的公司在虚拟现实技术上的探索，如今以 Quest、Pico 为代表 VR 一体机以其低廉的价格策略一举打入消费级市场，全新的技术需要与之匹配的人机交互方案，<strong>VR 手柄</strong> 和 <strong>手势识别</strong> 成为当前的通用方案</p><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141238439.png" alt="Untitled"/><p>放眼未来，还有一些更激进的探索，比如马斯克的 Neuralink，试图通过 <strong>脑机接口</strong> 技术实现人脑与计算设备的无缝连接。</p><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141239529.png" alt="Untitled"/><p>但这些，都尚不足以构成第三次人机交互革命。</p><h3>2.1 语音交互</h3><p>随着语音识别技术的发展，语音交互成为了可能。在某些场景下语音交互的效率要高于触摸交互，比如通过 Siri 的设定闹铃，但对人类意图理解的局限往往让 Siri 显得智障。除了语音交互可用性问题外，语音交互还受到社会文化的制约，比如你在私密聊天的时候并不想周围的人听到你在输入什么，整天对着电脑说话好像也比较奇怪（<a href="https://www.bilibili.com/video/BV1oW411P7Bi?share_source=copy_web&vd_source=bed4496723c23e402bf7cb38beab5916&t=475">参见老罗的TNT产品发布</a>）。这也解释了为什么当前以语音交互为主的设备主要集中在了家庭环境的智能音箱，如 Homepod，Alexa，小爱同学等。</p><p>即使如此语音交互在当前仍然是一种重要的人机交互方式，特别是在某些场景无法使用屏幕交互的场景下。所有人在某些时候都是残障人士，比如你在驾驶时、在厨房做菜时，手握方向盘或菜刀的你在某种程度上是肢体残障的，无法通过手来交互设备，只能通过语音进行。</p><p>这也引入了当前人机交互的一个重要趋势：<strong>多模态交互</strong>（Multimodal Interaction），即用户可以在不同的输入和设备输出中任意切换。</p><p>同样的输入既可以用触碰进行，也可以用语音进行，输入法就是一个很好的例子（尤其是 iOS16 更新了语音和触碰同时输入的功能）。</p><p>同理，内容的输入也可以在视觉、听觉中任意切换，比如微信读书既可以读书，也可以听书。</p><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141239554.png" alt="Untitled"/><h3>2.2 环境感知</h3><p>随着各种感知技术的进步，机器可以理解环境并主动提供服务。比如输入手机密码这个环节，通过 FaceID 或 TouchID 这样的生物识别技术就可以主动帮助用户解锁设备，省去了用户的操作步骤。</p><blockquote><p>最好的用户界面就是无界面 ——Golden Krishna</p></blockquote><p>环境感知的一个重要应用是在自动驾驶/辅助驾驶，通过雷达传感器或摄像头图像识别，汽车可以自己行驶并根据环境的变化主动做出调节，这个时候人类事无巨细的执行者变成了机器的监督者，从原来的高注意力状态解放出来，从中心注意力转至边缘注意力，但同时允许人类从边缘注意力随时切换到中心注意力接管汽车的操控。</p><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141239006.png" alt="Untitled"/><p>这也引发了人机交互的重要思潮：人机交互并不是用海量的内容去不断消费人类的注意力，而是让人类从中解放出来，但当前诸多移动互联网产品出于商业化考量而做出的产品设计与这一理念背道而驰。</p><p>在环境感知上一个成功的商业案例是 AirPods，一个剪掉线的耳机就可以卖出上千元的高价，还卖得这么好，离不开其无微不至的细节设计，离不开其借助环境感知帮助用户做出了很多选择。用户只要戴上耳机就可以连接上设备，摘下耳机设备的音乐就会停止播放，无需用户的操作，一切恰到好处。</p><p><a href="https://www.bilibili.com/video/BV1Tb411j7pf/?spm_id_from=..search-card.all.click">【何同学】听～妙不可言 不被看好的AirPods为什么成功了？<em>哔哩哔哩</em>bilibili</a></p><h3>2.3 设备互联</h3><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212141239308.png" alt="Untitled"/><p>我们这个时代并不缺少计算设备，而问题恰恰是由太多计算设备了。手机、平板、电脑、手表、汽车、智能家居，在不同场景下我们需要使用不同的设备，但倘若这些设备之间都是一座孤岛，那将是一场灾难：你不得不在不同的设备间重复相同的操作（如输入账号，存储文件等）。</p><p>好在这些设备都可以联网，为设备互联提供了可能，让用户可以在这些设备间无缝切换。甚至可以让设备发挥出 1+1&gt;2 的能力，比如华为在今年演示的利用手机和电脑的互联，使用电脑为手机提供计算能力。</p><p><a href="https://www.bilibili.com/video/BV1wG411h729?share_source=copy_web&vd_source=bed4496723c23e402bf7cb38beab5916&t=1536">【发布会回放】HarmonyOS 3及华为全场景发布会（完整版）<em>哔哩哔哩</em>bilibili</a></p><p>如果你看近些年的科技发布会，很多时候都是在强调设备间的连通，无论是苹果的接力或是隔空播放，还是华为的 1+8+N 布局。厂商们总想在全场景获取用户，当然这样做也无可厚非，无论是用户体验考量，还是商业利益都是成功的。</p><p>这也是为什么大的科技公司都在强调生态，也出现了手机厂商诸如小米去造汽车，汽车厂商诸如吉利/蔚来宣称要造手机。如今的用户早已不再是和单一的计算机交互，而是跟周围的一堆设备进行交互，甚至有人建议要把人机交互（HCI）研究领域切换至 <strong>人与环境的交互</strong>（HEI）。</p><h3>2.4 VR 和 AR</h3><p>虚拟现实将人机交互从 2D 屏幕带到了 3D 世界，所采用的交互方案也截然不同。普遍来看采用的是手柄控制器，在手柄控制器可以追踪手的运动，也有丰富的按键模拟抓握等手指交互，通过手柄震动提供足够的反馈。</p><p>但通过手柄交互并不自然，用户需要始终握持手柄，为此厂商也出了很多实验性的方案。其中有代表性的就是手势识别，通过 VR 头显上的摄像头捕捉手部的动作，实现隔空操作。其技术远未成熟，其一，通过摄像头追踪手部动作捕获范围有限，当手超出摄像头可见区变无法跟踪，其二，隔空手势交互无法提供足够的反馈，虽然可以通过声音来弥补，但仍然触觉的缺憾，其三，人的手在没有支撑下悬空交互非常累人（这也是 Macbook 至今没有支持触摸屏的原因之一）。</p><p><a href="https://www.bilibili.com/video/BV1oJ411K7mP/?spm_id_from=333.788.recommend_more_video.0&vd_source=8e3c34b67ebbc38fc462b554c7b1f806">【手势追踪】加量不加价！Hand Tracking on Oculus Quest <em> Oculus Connect 6</em>哔哩哔哩_bilibili</a></p><p>当然，考虑到手势识别是最自然的交互方式，厂家也在这一领域不断探索，从 21 年 Meta Connect 发布的实验性腕带技术可见一斑。</p><p><a href="https://www.bilibili.com/video/BV1xD4y1k7PZ?share_source=copy_web&vd_source=bed4496723c23e402bf7cb38beab5916&t=4171">2022年Meta Connect直播回放_哔哩哔哩bilibili</a></p><p>人们对虚拟现实的应用场景绝不仅限在游戏场景，新冠大流行后远程办公有了巨大的需求，虚拟现实也想在生产力场景下有一番作为。提到生产力，免不了文字输入，VR 下隔空操作虚拟键盘实在效率低下，语音输入又有诸多限制，在这一背景下 VR 厂商也做了一些有趣的尝试，在较新的 Quest 版本中，支持头显蓝牙连接键盘，并且在虚拟世界中将实体键盘复刻出来，让用户在虚拟世界也能看到所操作的键盘，这种探索进一步模糊了虚拟与现实的边界。</p><p><a href="https://www.bilibili.com/video/BV1PM4y1u7zX/?spm_id_from=..search-card.all.click&vd_source=8e3c34b67ebbc38fc462b554c7b1f806">【VR】你们一定都想过用VR替代显示器，今天我们试试，oculus quest 2尝试轻办公,在VR中看B站，在VR中打字回复消息.V29系统版本支持蓝牙键盘，<em>哔哩哔哩</em>bilibili</a></p><p>打破虚拟和现实边界的当然还有增强现实技术（AR），传统的设备和现实环境之间仍然是分隔的，比如使用导航时，需要一边看手机屏幕，一边看路面，而增强现实可以融合这二者让一切变得更加自然。当前的增强现实还是局限在通过手机屏幕为载体，通过摄像头感知周围的环境，但从 Google Glass 到 Microsoft HoloLens，人们一直没有放弃对更强大的增强现实技术的探索。</p><h3>2.5 脑机接口</h3><p>如果说人机交互有终极目标，那么脑机接口可能是很多人想象中的答案。这一领域其实已经很久了，但破译大脑的秘密确实是世界级难题，虽然在 2014 年巴西世界杯上就有通过脑机技术让残疾人士控制机甲完成世界杯开球的壮举，但这一技术举例大众的生活仍然很远。</p><p>让这一领域再次进入人们视线可能要归功于顶流马斯克的助力，其下的 Neuralink 致力于让脑机互连成为可能，但诚如马斯克自己所说，这是一个非常有雄心的目标，需要很多年时间，其阶段性目标也仅仅是帮助残障人士。</p><p><a href="https://www.bilibili.com/video/BV1rK411F76b/?spm_id_from=..search-card.all.click&vd_source=8e3c34b67ebbc38fc462b554c7b1f806">马斯克的Neuralink脑机接口新实验，猕猴通过植入芯片玩《Pong》游戏 @柚子木字幕组<em>哔哩哔哩</em>bilibili</a></p><p>脑机接口总的来说从功能上分为大脑读取和写入两种，前者寄希望翻译神经信号，已经困难重重，后者更是暂无头绪。从形态上看，脑机接口分为侵入式和非侵入式两种形态，前者需要将传感线植入大脑，这一点对大范围应用就有很大的阻碍，而后者又会收到各种噪音的影响，精准程度大不如前者。</p><p>就消费级应用来看，脑机接口还很远，但不妨碍他作为如人机交互圣杯这样的存在，因为有梦想总是好的，万一哪天实现了呢。</p><h2>三、未来交互思考</h2><p>很多时候我们会被一些很酷的人机交互吸引，比如 Google Glass 刚出来那会儿，又比如科幻电影里面的各种全息影像，但好的人机交互不应该看起来酷就够了，更重要的是要思考其解决了什么问题，以及可能带来什么问题。</p><blockquote><p>真正对人机交互产生革命性影响的绝不仅仅是一种具体的交互形式，而是这背后所蕴藏的设计理念和思考。</p></blockquote><p>正如桌面比喻和纸本范式这一设计理念对当今人机交互的深远影响，未来革命性的人机交互模式也需要有其核心的设计理念，因为人机交互本身不是问题，只是解决问题的方式。</p><p>在当前的人机交互演进中，我们可以看到多模态交互，环境感知，万物互联这些趋势对人机交互形态重要影响，可看到 VR/AR 的各种前沿探索，虽然新的变革性人机交互模式尚未出现，但我们有理由相信，第三次人机交互革命正在发生。</p><p>什么是真正好的人机交互？回到 <strong>Mark Weiser</strong> 在 <strong>平静技术</strong>（Clam Technology）中的思想可能会给我们一些启示，虽然他并没有亲历移动互联网浪潮，甚至没有见过智能手机，但他早已预见海量计算设备充斥在人们的生活中，而好的人机交互应该如「文字」一样进入我们的生活中，并消失在我们的生活中。</p><blockquote><p><strong>最深刻的科技是那些能够消失的。它们把自身编织进日常生活的千丝万缕之中，直到它们再也无从辨别。</strong></p></blockquote><hr><h3>参考资料</h3><p><a href="https://sspai.com/post/66647">人机交互的三次革命（一） - 少数派</a></p><p><a href="https://www.zhihu.com/question/25368358">知乎问题</a></p><p><a href="https://calmtech.com/papers/computer-for-the-21st-century.html">Calm Technology</a></p>]]></content:encoded></item><item><guid isPermaLink="true">https://taofuns.github.io/posts/The%20logic%20behind%20OpenAI</guid><title>The logic behind OpenAI</title><description></description><link>https://taofuns.github.io/posts/The%20logic%20behind%20OpenAI</link><pubDate>Wed, 22 May 2024 12:29:23 +0800</pubDate><content:encoded><![CDATA[<p>#Software/ChatGPT #Fn/Post</p><p>2023 年 11 月 6 日 OpenAI 举办了自其成立近八年来的首次开发者大会 DevDay[^1]，在这个月的月底也将迎来旗下现象级产品 ChatGPT 发布一周年[^2]。在过去的一年里，OpenAI 狂奔猛进，年收入从 2022 年的 2800 万美元迅速迈向 2023 年的 10 亿美元[^3]，其公司市值一年内翻了好几倍，预计将达到 800 亿美元[^4]。OpenAI 已经成为科技圈的先驱力量，在 DevDay 的 Keynote 上 Sam 提到 ChatGPT 周活达到 1 个亿，OpenAI 的 API 平台也已经拥有 200 万开发者 [^5]。 ![[image 43.png]]</p><p>OpenAI 的发展太快了，暂且不论人家四天时间可以换三次 CEO 的戏剧情节[^6]，光看双周迭代的 <a href="https://help.openai.com/en/articles/6825453-chatgpt-release-notes">ChatGPT 更新日志</a> 也容易让不直接身处该行业的人感到目眩神迷，看不清未来的方向，只能被动得接受一个又一个新闻大事件。然而，不同的事件之间往往有千丝万缕的联系，剖开现象的外表，总可以觅见事物发展的一些基本逻辑。<strong>本文旨在在此方向上做出一些尝试，回到用户视角、回到开发者视角、回到公司视角，通过 OpenAI 过去尤其是最近一年的种种动作理解其背后的基本逻辑。</strong></p><h2>用户想要什么</h2><p>在DevDay 上，OpenAI 展示了 ChatGPT 的新能力。一般情况下，ChatGPT 的能力要比面向开发者的 API 更提前一些放出来，这一方面可以方便管控风险，另一方面也是给调用与 ChatGPT 相同底层模型开发者提供示范。ChatGPT 的更新中令人最印象深刻的要数 GPTs 了，它可以让用户以极低的成本创建个性化的GPT，同时能够调用外部知识库并使用工具[^7]。可以将 GPTs 看作是 ChatGPT 在既有的<a href="https://openai.com/blog/chatgpt-plugins">插件（Plugins）</a>和 <a href="https://openai.com/blog/custom-instructions-for-chatgpt">个性化指导语（Custom instructions）</a>功能上的融合与升级。晚些时候将推出的 GPTs Store 更是打开了 ChatGPT 生态的想象空间。从用户的热情来看，ChatGPT 本次的更新也是成功的，由于访问量激增影响了服务的稳定[^8]，ChatGPT不得不随后关闭 Plus 的订阅通道。 ![[image 3 2.png]]</p><p>ChatGPT 带来了人与机器通过自然语言交互的可能，人们起先可能只是把它当作<strong>玩具</strong>，看看它能做什么，随着发现它能将越来越多原先认为它不能做的东西竟然能做，人们对他的期待也就越来越高，希望它能够成为真正有用的<strong>工具</strong>。从玩具到工具，便是 ChatGPT 的进化之路。 ![[image 4 2.png]]</p><h3>更有效的回复</h3><p>ChatGPT 的背后是一个语言模型，简单来说就是让它通过阅读大量的现有文本学习到语言的规律，使其能不断根据已知文本预测后续文本[^9]。人类通过一种叫做<a href="https://openai.com/research/instruction-following">RLHF方法</a>的调教，让它学会了如何像人类一样对话。</p><p>虽然 ChatGPT 能跟人流畅得对话，但其回复不一定是准确的，而且其一本正经得胡说八道的能力甚至让你对其产出的结果难分真假。</p><p>如同「You are what you eat」, 为了具备更强大的语言能力，它需要去阅读更大量的有效文本，经过更复杂的训练产出更强大的模型。所以<strong>模型升级是 ChatGPT 作为工具提升其有效性的主旋律</strong>，从GPT3.5 到 GPT4 Turbo，ChatGPT 背后的模型一直在升级，更强大的模型也带来更大范围的上下文理解能力，解锁更多使用的场景[^10]，所以纵使在用户界面的功能上没看到什么变化，实际耍起来就还是可以明显感受到其能力的进步。</p><h3>更快捷地使用</h3><p>如果把 ChatGPT 看成一个个人助理，不同用户对其所心仪的助理的人格要求并不一样，使用同一个样板助理服务所有用户很难尽善尽美，这就诞生了通过某种方式个性化ChatGPT的需求。 ![[image 5 2.png]]</p><p>ChatGPT 与人类的自然语言对话建立在能听懂人类所提供的指导语的基础上，而提供有效的指导语是产出理想回答的关键，通常我们调教 ChatGPT 的方式就是在新建立对话后通过语言给他催眠一个人设，这也催生了<a href="https://platform.openai.com/docs/guides/prompt-engineering">提示词工程 （Prompt engineering）</a>这一研究领域。</p><p>为了让这个过程更加快捷，ChatGPT 做的第一个尝试是添加了<a href="https://openai.com/blog/custom-instructions-for-chatgpt">个性化指导语（Custom instructions）</a>的功能，可以全局给 ChatGPT 赋予一个人设。 ![[image 6 2.png]]</p><p>然而写出好的提示词并不是一件容易的事，虽然网上可以找到别人总结提炼好的提示词，但是不同的用户毕竟有不同的细分场景，<a href="https://openai.com/blog/introducing-gpts">GPTs</a> 的出现用更优雅的方式解决了这个问题：让 ChatGPT 引导你如何调教它自己。另外，通过 GPTs 的交互设计让一个用户可以拥有多个不同人格的助理。 ![[image 7 2.png]]</p><h3>更多元的交互</h3><p>人类之间的交互并不限于文字，甚至很多内容光靠文字无法高效表达，多模态的交互方式（图片、音频、视频等）是解锁人机交互可能性和提升易用性的关键。</p><p>虽然在 2023 年 3 月份 <a href="https://openai.com/research/gpt-4">GPT-4</a>的发布会上 OpenAI 便演示了 GPT 的图像理解能力[^11]，但直到 9 月底，ChatGPT 才真正上线了图像理解能力，并同时支持了对话交流的能力[^12] 。随后的 10 月份，ChatGPT将图像生成模型 DALL·E 3 整合进 ChatGPT[^13]。</p><p>在 11 月份的 DevDay上，OpenAI演示了最新的TTS能力，其背后的支撑技术来自于 Whisper 模型，最令人惊艳的是其合成出来的声音听起来非常自然，并且支持多种语言。 ![[image 8 2.png]]</p><p>多元的交互方式对用户而言是感知很明显的功能，其背后是 OpenAI 研究多年的多种不同生成模型[^14]在用户体验的融合，也让原来分散的模型产出协同的力量。</p><h3>更强大的能力</h3><p>今天的语言模型虽然可以完成各种各样的任务，但仍有限。他们唯一能学到的信息是他们的训练数据。这些信息可能已经过时，并且不适合所有任务。另外，语言模型的最终产出就是发出文本，如果用户想获取关于某个问题的指导，虽然语言模型输出的文本可能包含有用的说明，但要实际遵循这些说明，用户需要进入另一个流程。</p><p>现实世界的互联网其实有非常多有用的工具，只是这些和语言模型割裂开来，如果教会语言模型去使用工具，那么将可以解锁更多的可能性[^15]。<a href="https://openai.com/blog/chatgpt-plugins">ChatGPT 插件</a>便是在这样的背景下诞生了。 ![[image 9 3.png]]</p><p>有了浏览器插件，ChatGPT 可以搜索互联网找到更具有时效性的信息用以回应用户[^16]，有了代码解释器插件，ChatGPT 便可以自主写 Python 代码帮助用户完成特定的数据任务，有了检索插件，ChatGPT 便可以不仅限于学习公域的数据，还可以通过语义搜索对用户提供的私人数据进行学习[^17]。</p><p>插件的核心是<a href="https://platform.openai.com/docs/guides/function-calling">函数调用（Function Calling）</a>，允许 ChatGPT 借助语言模型的能力，根据所处的上下文智能生成特定的代码，从而调用外部的 API，再把获取到的返回结果加工后吐给用户。</p><p>随着 DevDay 上 <a href="https://openai.com/blog/introducing-gpts">GPTs</a>的发布，ChatGPT 插件将退出历史舞台（至今也只有 160 个插件），其函数调用的功能被整合进GPTs的<a href="https://platform.openai.com/docs/assistants/tools">工具箱（Tool）</a>中，原先的插件商店已经不再接受新插件的提交[^18]，所担负的使命将由未来的 GPTs Store所承载。</p><p>从用户体验上来看，新的GPTs的交互逻辑相比原先的插件也更符合直觉，调用工具能力也更加简单，甚至不用写代码，直接上传一些文档就可以获得对私人文档（<a href="https://platform.openai.com/docs/assistants/tools/knowledge-retrieval">支持多种格式</a>）的寓语义搜索能力。 ![[image 10 3.png]]</p><h3>更安全的环境</h3><p>自 ChatGPT 诞生之初，媒体上就不断有关于各种企业因为数据安全问题禁止员工使用 ChatGPT 的报道。人们担心 OpenAI 利用他们和 ChatGPT 的对话进行数据训练，而事实却是如此，在 OpenAI 的相关使用条款[^19]中明确写道 ChatGPT这类直接面向消费者的产品其数据如不经过特殊设置默认是会用于训练以提升模型（除非关闭对话记录功能）[^20]，在某些情况下甚至可以直接查看用户的对话数据。</p><p>然而如果没有数据安全，就很难获得企业客户，所以在 8 月份的时候 ChatGPT发布了<a href="https://openai.com/blog/introducing-chatgpt-enterprise">企业版</a>，并承诺企业版和开发者的数据是私有的不会用于训练。</p><h2>开发者想要什么</h2><p>开发者大会的第一受众是 OpenAI 的开发者，对他们来说主要关心两点：</p><ul><li>能否让他们做以前无法做到的事情；</li><li>能否让以前可以做到的事情更容易；</li></ul><p>从这两点来说，这次开发者大会都是成功的，Sam 分别讲解了更新的能力，总结来说就是：更强大的模型，更友好的开发，更多元的模态，更定制的方案，更便宜的价格[^21]。 ![[image 2 2.png]]</p><h3>更强大的模型</h3><p>OpenAI 在 3 月份刚发布 GPT-4， 并于 7 月份向开发者全量。如今已经将模型更新到 GPT-4 Turbo。GPT-4 Turbo能力更强大，并了解截至2023年4月的数据。它有一个 128K Token 的上下文窗口，因此它可以在单个提示中容纳相当于300多页文本。</p><p>上下文窗口的大小就像是电脑的内存一样，决定着语言模型处理一次数据的内容广度，比如最初的普通版 GPT-4 只有 8K 的 Token，不经过特殊处理只能帮你摘要一篇公众号文章，现在已经可以帮你摘要一本书了。</p><p>连接语言模型和外部工具的桥梁是<a href="https://platform.openai.com/docs/guides/function-calling">函数调用</a> ，不同于传统客户端需要由程序员手搓代码写好调用逻辑，语言模型可以自主根据用户请求的自然语言分析需要调用的函数（由开发者提供 API 描述文件即可，类似在 GPTs 中添加工具），并且智能在自然语言中提炼出所需要的参数，而这一切的准确性都得到了提升，并且支持在一个请求中调用多个不同的函数。比如在我们的数据平台里面添加个智能助手，用户发出请求后，智能助手能不能调用我们自己平台的接口完成任务就很依赖语言模型函数调用的能力。</p><h3>更友好的开发</h3><p>虽然平台方提供了基本接口能力后，厉害的开发者可以叠上时间和精力通过奇技淫巧实现卓越的效果，但平台的下限，或是说整个生态的平均水平其实是由平台提供的开发框架的易用性决定的。</p><p>DevDay 上 OpenAI 发布了 <a href="https://platform.openai.com/docs/assistants/overview">Assistants API</a> ，它可以帮助开发人员很方便在自己的应用程序中构建初步的特定功能的智能助手。这种助手具有特定的指令，可以利用自由的知识库，并且可以调用模型和工具来执行任务。新的Assistants API提供了新功能，如代码解释器、检索以及函数调用，这些原先自己做的许多繁重的工作来处理，现在一两行代码就搞定了，就像是用户在 ChatGPT 上创建 GPTs一样轻松。</p><h3>更多元的模态</h3><p>之前的 GPT-4 只有文字处理能力，而GPT-4 Turbo可以接受<a href="https://platform.openai.com/docs/guides/vision">图像</a>作为 API 的输入，可以让 AI 理解图像内容，也可以通过 DALL·E 3 通过文字<a href="https://platform.openai.com/docs/guides/images?context=node">生成图片</a>。</p><p>开发者现在也可以通过 <a href="https://platform.openai.com/docs/guides/text-to-speech">TTS （文字转语音）</a>API 从文本中生成人类质量的语音，如果ChatGPT 所演示的那样，新的 TTS 模型听起来非常像真人，及时是非英语语音，与有不错的表现。</p><p>多模态让用户与产品的交互有更多可能性，开发者也可以借助同样的模型实现 ChatGPT 所具有的多模态能力。</p><h3>更定制的方案</h3><p>针对特定的需求，为了获得更好的表现，一般要有更定制化的模型。技术上有两种方式来实现：</p><ul><li>一种就是训练自己的模型，这不仅成本高，需要大量数据，还是个技术狠活 ，据称研究训练一个 GPT-4，其花费就超过了 5 亿美元[^3]；</li><li>另一种是在已有模型的基础上进行<a href="https://platform.openai.com/docs/guides/fine-tuning">精调（Fine-tuning）</a>，所谓的精调通俗理解就是向模型展示优秀实力，让模型「看我做，跟我学」，一般提供成百上千对示范就能获得不错的效果，大多数的开发者都是用这种方式；</li></ul><p>在本次 DevDay 上，这两种定制化方案都得到了支持与增强。对于精调，过去只支持GPT-3.5，现在终于支持 GPT-4 了。对于需要比精调更多定制的组织（特别适用于具有极大型专有数据集，毕竟现有GPT用的大多数还是公开数据[^9]），OpenAI 还启动了一个自定义模型计划，使选定的组织有机会与一组专门的OpenAI研究人员合作，将自定义GPT-4培训到其特定领域 （起步价两三百万美刀，训练耗时数月）。</p><p>似乎 OpenAI 和百度的李彦宏一样，在说 「做大模型，我是专业的，你们不要再卷大模型了，在我的上层做应用就好了」。</p><h3>更便宜的价格</h3><p>GPT-4 Turbo 比 GPT-4 更加强大，但是费用更低，输入Token价格为0.01美元，比GPT-4便宜3倍，输出Token价格为0.03美元，便宜2倍。</p><p>除了 GPT-4，全平台的各种模型和相应的能力费用都下调，除此之外，对于单位时间内的<a href="https://platform.openai.com/account/limits">请求量</a>也有相应的提升。</p><p>通过这一系列组合拳，可以降低开发者使用 OpenAI API 的门槛，也是对同类型竞争对手的回应。</p><h2>OpenAI 想要什么</h2><p>OpenAI 目前的商业模式是“一鱼两吃”型，基于底层的技术能力提供了 ChatGPT 和 API 两种服务[^22]，这些服务的各个组成部分恰恰是连接用户需求和技术能力的纽带，其所提供的服务既取决于技术能力，也取决于用户需求，毕竟不能拿着技术当锤子去发明需求。</p><h2><img src="image2.png%201.webp"/></h2><p>如果 OpenAI 就是如同谷歌、苹果一样的商业公司，倒也好理解，但拉远视角，才能看见 OpenAI 独特的治理结构[^23]，虽然拥有ChatGPT和API平台的 OpenAI 是营利性组织，但其受非盈利的母公司领导，并且该公司的存在是为了推进实现其非营利组织使命——构建安全且惠及全人类的通用人工智能（AGI）[^24]。可能也只有在这一框架下才能更好理解 OpenAI 的种种逻辑。 ![[image 11 2.png]]</p><h3>安全且惠及全人类的 AGI</h3><p>OpenAI 定义的 AGI 是指在最经济上有价值的工作上优于人类的高度自主系统[^25]。从现在来看，显然还没有实现 AGI，但是 OpenAI 是相信 AGI 会来到的，甚至最初来到这家使命驱动的公司工作的人也是专挑 AGI 信仰者[^26]。</p><p>也只有 AGI 的信仰者才会真正意识到 AI 的危险，如果实现了 AGI，人工智能会以越来越快的速度重新设计自己的能力，不可阻挡的“智能体爆炸”可能导致人类灭绝，曾经的OpenAI创始人马斯克也将人工智能描述为人类“最大的生存威胁”。</p><p>OpenAI 在语言模型上的成功实践给人们更多信心，虽然不确定大语言模型是不是通往 AGI 的道路，也不确定需要多久才能实现 AGI，但 OpenAI 认为在这种事情上以存在 AI 风险作为前提假设更为理性。</p><p>除此之外，强大的 AI 会在很多方面对人类社会造成影响，人类也需要时间来逐步适应。从Sam 在 OpenAI 路线图的解释中可以看到，他们认为为了让AGI造福人类需要让人类逐渐使用威力较弱的技术开始，然后不断克服过程中的问题，而不是只给人类一次做对的机会[^27]。</p><p>在一档播客中，Sam进一步解释说原本ChatGPT是要和GPT-4一起推出的，但是盘算了一下觉得社会可能一下子没法消化这么多，于是拆分出来，用还没那么先进GPT3.5-Turbo来做实验[^28]。（也有传言说 OpenAI是看到其竞争对手 Anthropic 正在开发聊天机器人而临时决定在几周内要上线ChatGPT的[^29]）</p><p>在语言模型上，OpenAI 已经找到<a href="https://openai.com/blog/our-approach-to-alignment-research">一定方法</a>来使得 AI 符合人类的价值体系，<a href="https://openai.com/research/instruction-following">这种方法</a>的实践也促使了 ChatGPT 的诞生，OpenAI 也通过 ChatGPT 来搜集数据，学习真实的人类与 AI 间的互动以确保更好管控风险。</p><p>OpenAI 还希望 AGI 能够对所有人可用，虽然它已经不那么Open了，但是通过 API 的方式将自己的能力开放出来，让所有开发者都可以使用，这也要求 OpenAI 将自身能力与开放能力保持同步，否则最初以反大公司垄断 AI 而诞生的 OpenAI 岂不是自己打自己脸，屠龙少年终成恶龙 （为了约束 OpenAI 变成恶龙，他们设计了由不含股权的董事构成的董事会控制公司的架构，这也是近期董事会罢免 Sam 的治理基础[^23]）。</p><h3>保证自己的技术领导力</h3><p>OpenAI 认为为了有效解决AGI对社会的影响，仅靠政策和安全倡导是不够的，OpenAI必须处于人工智能能力的前沿，拳头大才是硬道理，甚至在OpenAI的宪章中还提到如果一个符合价值、有安全意识的项目在他们之前接近建立AGI，他们承诺停止与该项目竞争并开始协助该项目[^25]。所以他们不仅做 AGI 相关的研究，也直接下场构建强大的 AI 系统。在成立最初几年的实践中，他们发现这些工作需要大量的金钱[^30]，而仅靠捐助来获得资金的方式并不奏效（最初募资10亿美元实际到账1亿多），所以他们设计了前文提到的这个独特的治理结构[^23]。</p><p>ChatGPT 是当前最前沿的 AI 产品就是这一技术领导力的体现，但我想这款产品对 OpenAI 来说一个破局点。其实，ChatGPT的火爆程度是也超出 OpenAI 自己预料的，因为在开发产品的工程师眼里，其所使用的技术<a href="https://openai.com/research/instruction-following">InstructGPT</a>早已存在，并且还有相应的API供开发者调用[^31]。ChatGPT的成功带飞了 OpenAI 的营收，打开了其盈利模式，根据OpenAI的营收报道粗略估算，目前ChatGPT Plus的渗透率也仅有 2% 左右，随着Plus功能差异性越来越显著，用户付费动机也会更强，更多的付费用户可以获得更多数据反馈，也可以摊薄大模型的训练成本，以获得更强大的模型，吸引更多的用户和开发者，这样的商业正向闭环就构建出来了（所以ChatGPT Plus还是会再开放的）。</p><p>在 OpenAI 产品与服务狂奔猛进之际，如何在资源有限的情况下，平衡<strong>构建强大的AI系统</strong>和<strong>建立有效的安全机制</strong>之间的冲突也显得尤为突出。</p><p>OpenAI CEO <a href="https://www.youtube.com/watch?v=ao5uDR3JyA0">Sam</a> 和首席科学家 <a href="https://www.youtube.com/watch?v=Ft0gTO2K85A&t=115s">Ilya</a> 最近在不同场合都透露过 OpenAI 在技术上取得了重大进展，似乎人类朝着 AGI 的方向更进一步。也有传言说是最近取得的人工智能突破可能会对人类产生威胁[^32]，对于安全地构建 AI 系统的分歧似乎也是导致这次 Sam 被戏剧性解雇的核心原因。</p><h2>附录</h2><h3>FAQ</h3><p><strong>Q：GTPs出现前后，ChatGPT解决的问题场景有何不同</strong> A：可以将 GPTs 看作是 ChatGPT 在既有的<a href="https://openai.com/blog/chatgpt-plugins">插件（Plugins）</a>和 <a href="https://openai.com/blog/custom-instructions-for-chatgpt">个性化指导语（Custom instructions）</a>功能上的融合与升级。插件解决了语言模型与现实世界隔离的问题，插件使得语言模型能够使用工具，使得语言模型具有更强大的能力适应更多的任务场景。个性化指导语解决了ChatGPT统一的默认设置带来的限制，让用户轻松改变他们正在使用的人工智能的行为，得以让 AI 更好服务于人[^27]。</p><p><strong>Q：有没有什么新出现的场景和新的机会</strong> A：对于中小企业来说，可以用更低的开发门槛和更低的价格使用 OpenAI 的 API，相对原先也可以调用更多模态的能力（图片、TTS），还更容易将语言模型与自己的私有数据和接口连接起来。对于大型企业来说，可以借用 OpenAI 在大模型上的积累，让其帮自己用自己的数据以更低的成本训练达到 GPT-4 水平的语言模型。</p><p><strong>Q：外界对此次发布的声音有哪些，比如对ai创业项目的影响等等</strong> A：随着 OpenAI 模型的继续领先，训练与之媲美的模型成本会越来越高，在生成式 AI 创业卷着去做基础模型会越来越难，而另一方面使用现有模型的成本越来越低，性能越来越好，会有越来越多基于生成式 AI 能力的应用出现。</p><h3>研究方法</h3><ol><li>通过书籍和课程了解AI的发展</li><li>深度体验ChatGPT</li><li>看OpenAI相关发布会</li><li>简单上手OpenAI API</li><li>通过OpenAI自己的 Blog 和 Research了解历史沿革</li><li>通过媒体报道了解公司与产品的幕后</li><li>体验相关竞品</li></ol><h3>延伸阅读</h3><p>产品 <a href="https://help.openai.com/en/">OpenAI 的帮助文档，有很多文章帮助了解产品细节</a> <a href="https://openai.com/blog">OpenAI 的博客，可以从时间线了解其发展历程</a> <a href="https://www.youtube.com/@OpenAI">Youtube 上的 OpenAI 官方账号，存有各次重要的发布会</a></p><p>开发 <a href="https://platform.openai.com/docs/overview">OpenAI 面向开发者的文档，可以通过开发者视角了解 ChatGPT 如何工作的</a> <a href="https://platform.openai.com/docs/api-reference">OpenAI 面向开发者的 API 参考，偏技术，是文档的延伸</a> <a href="https://github.com/openai">Github 上的 OpenAI 官方账号，有不少示例代码和技术说明</a> <a href="https://community.openai.com/categories">OpenAI 开发者社区</a></p><p>研究 <a href="https://openai.com/research">OpenAI 发表的研究论文</a> <a href="https://www.deeplearning.ai/short-courses/">吴恩达做的生成式 AI 简明课程</a></p><h2>参考资料</h2>]]></content:encoded></item><item><guid isPermaLink="true">https://taofuns.github.io/posts/first-post</guid><title>Apple official tutorials</title><description>Tutorials by Apple</description><link>https://taofuns.github.io/posts/first-post</link><pubDate>Mon, 11 Sep 2023 21:24:00 +0800</pubDate><content:encoded><![CDATA[<h1>Apple official tutorials</h1><p>Apple has used <code>DocC</code> creating some great tutorials, list as below.</p><ul><li><a href="https://developer.apple.com/tutorials/swiftui">#1 Introducing SwiftUI (Xcode13)</a></li><li><a href="https://developer.apple.com/tutorials/swiftui-concepts">#2 Learning SwiftUI (Xcode14)</a></li><li><a href="https://developer.apple.com/tutorials/app-dev-training#drawing">#3 Build Scrum (Xcode14)</a></li><li><a href="https://developer.apple.com/tutorials/sample-apps">#4 Exploring SwiftUI Sample Apps</a></li></ul><p>Among them, <code>Exploring SwiftUI Sample Apps</code> can also be found in Swift Playgrounds app.</p><p>What's more, apple has published a series of books called <a href="https://books.apple.com/us/book-series/develop-in-swift/id1483863177">Developer in Swift</a> in Apple Books, however, it uses UIKit which is a bit old.</p>]]></content:encoded></item><item><guid isPermaLink="true">https://taofuns.github.io/posts/%E4%BB%8E%E5%8D%A1%E7%89%87%E7%AC%94%E8%AE%B0%E5%88%B0Obsidian%EF%BC%9A%E6%9C%AC%E8%B4%A8%E3%80%81%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E5%85%B7</guid><title>从卡片笔记到Obsidian：本质、方法与工具</title><description>Tutorials by Apple</description><link>https://taofuns.github.io/posts/%E4%BB%8E%E5%8D%A1%E7%89%87%E7%AC%94%E8%AE%B0%E5%88%B0Obsidian%EF%BC%9A%E6%9C%AC%E8%B4%A8%E3%80%81%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E5%85%B7</link><pubDate>Mon, 11 Sep 2023 21:24:00 +0800</pubDate><content:encoded><![CDATA[<h1>从卡片笔记到Obsidian：本质、方法与工具</h1><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212160214122.png" alt="Frame 3"/><p>本来记笔记是一件简单的事，但最近看了一些文章并体验了一些新的笔记应用反而让我多了些困惑，后来我才明白，困惑的不是如何更好地记笔记，而是如何更好地思考，笔记只是思考的具体结果。</p><p>好的笔记不应该是有了特定的工具才能写出来，厉害的人往往拿着简单的纸笔也能高效思考，但从麦克卢汉媒介即讯息的角度来说，工具也在塑造我们思考的方式。</p><p>好的笔记方法也不应该只有特定的技巧才能达成，不同的人有不同的思考方式，采用不同的笔记方法也理所应当，但有效笔记方法的共性应该是大于差异性的。</p><p>从思考到笔记，冥冥之中应该有条互相关联的线，这是我想在这篇文章里探讨的。</p><h2>一、本质</h2><p>很多人提到了卢曼的卡片笔记法，刚开始接触的时候我被各种笔记术语以及复杂的编码系统整蒙圈了，但刨开特定的方法，卢曼卡片盒的本质就是将大问题拆成小问题，把知识管理流程中的收集、整理、连接、应用拆分成了有序的流程。</p><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212160128559.png" alt="Pasted image 20221216003932"/><h3>收集</h3><p>无论是灵感笔记还是文献笔记，本质上都是收集随时产生的想法。这些都是想到就写下来，因为有后续进一步的整理流程，所以写的时候不用有太大的压力，不用考虑想法是否成熟，不用在乎造词遣句，尽可能地降低记录的摩擦。</p><h3>整理</h3><p>并不是所有笔记都会被保留下来，收集来的笔记只有进一步的加工才会保存成永久笔记。很多人做笔记只有记，而没有整理，因为整理太难了，难在我们总想将笔记整理成文章，而写一篇文章哪是那么容易的事情，卢曼比较巧妙，把整理的产物定成了想法卡片这样的小目标，为卡片纸张大小的约束，让整理容易了很多，就像写一篇微博总比写一篇博客要简单。</p><h3>连接</h3><p>很多人记笔记就只是记下来了，然后再也就不用了，使得笔记成为记忆的坟场。为了让平时的积累能够被未来用的时候被看见，卢曼在纸笔时代通过复杂的编码体系将想法进行连接，以打破纸质卡片空间的距离。</p><h3>应用</h3><p>所谓成功无诀窍，工夫在平时，当卡片盒里某个内容相关的卡片到达一定数量，主题会自动涌现出来，写作的时候也就不是从一张白纸开始了，想象一下，你有一大堆纸质卡片，把他们摊在桌面上，然后不断组合连接，通过一定的逻辑就能组织成一篇文章，这便是自下而上的知识管理。</p><p><strong>卡片笔记法的本质是问题拆解，卢曼的拆解方法也确实巧妙。</strong></p><h2>二、方法</h2><h3>用卡片分类打造工作流</h3><p>卢曼卡片法中最重要的就是永久笔记，那是思想的源泉，但一下子就要写出有价值的想法是极具挑战性的，如果刚开始就以这个为目标，那么无疑会有着巨大的记录压力，甚至可能就不记了。</p><p>所以在笔记放入卡片盒之前，会有更轻量级的笔记卡片作为铺垫，无论是灵感笔记还是文献笔记，都只是转化为有价值的永久笔记前的过渡，每天我们都会有很多的想法，有的极具价值，有的经不起时间的考验，卡片盒便以仪式化地方式对这些想法进行了一层过滤。</p><p>相应的，写一篇文章也不是一件容易得事情，而卡片盒中的永久卡片也为后续的文章打下了提前量。</p><h3>卡片使得想法成为素材</h3><p>为了让记下来的想法能够在需要的时候被用起来，它应该能成为素材的一部分。素材有点像是软件工程里的 API，可以像组件一样放到不同的上下文中，实现想法的快速复用。</p><p>Andy 也在 Evergreen Note 中提到好的笔记应该是原子化的，应该只阐述某一特定主题，但对于这个粒度的把握简直就像一门艺术，而卡片因为纸张空间的限制，反而让对粒度的定义变得简单。</p><p>因为纸张不大，只能记这么多，所以写起来没那么复杂，又因为空间不足，你要表达清楚一定的主题，卡片的内容就需要经过大脑深度加工方才写下来。</p><p>卢曼卡片还要求一定要用自己的话来写永久笔记，因为只有自己写下来的东西才能完整明白自己在说什么，虽然增加了存写难度，但是未来提取会更容易，也为笔记的连接建立了前提。</p><h3>想法连接带来外脑思考</h3><p>人们往往都说功夫在平时，但是很少有人具体告诉你应该如何转化这些积累，卡片笔记链接解决了这些问题。</p><p>我们大脑的工作记忆是有限的，就像电脑的内存一样，同一时间只能想到那么多的东西，如果你尝试过头脑风暴，就会发现风暴了一段时间就很累也想不到更多东西，而记下来的笔记链接相当于用外部存储扩容内存，让人发现被忽略的东西，并且那些被链接的卡片本身就是平时积累下来的有价值的思考。</p><p>我们的大脑也有着证实偏好，更喜欢关注那些能证实我们观点的东西，而记下来的卡片有助于与自己的想法对话，相当于把这个想法从脑子中剥离出来，可以从他者的视角来重新审视。</p><p><strong>卢曼的方法虽巧妙，但也不要刻板地遵循其中具体的技术，他的方法建立在特定的时代背景下，卢曼复杂的编码系统、密密麻麻的索引表、甚至是永久笔记称之为“永久”都是以纸笔作为媒介前提的，而生活在数字时代下的我们有更多新的工具可以使用。</strong></p><h2>三、工具</h2><p>近几年很多人都在谈论双链笔记，也开始尝试使用双链笔记作为传统笔记应用的替代，不过工具只是工具，它替代不了你思考，即使没有双链笔记，只要你日常能够认真记录，及时整理，勤于输出也可以达到很好的思考效果。</p><p>但好的工具也确实能给我们带来不少方便，因为最近在使用 Obsidian，就结合上述的本质与方法简单聊聊我对它使用方式的理解。</p><h3>日记</h3><p>每天我们都有很多的想法，如果犹豫是否要记下来的时候，那么就应该把它记下来。</p><p>日记（DailyNotes）是一个很巧妙的设计，每天生成新的一页，每天也仅有一页。我认为它并不是我们传统理解的回顾一天的日记，而是随时记录下来某一刻的想法，这些想法是否成熟并不重要，它就是一种轻量的灵感笔记。</p><p>对于日记来说，最重要的两点就是快速记录与及时回顾。我自己是使用快捷指令搭配快捷键 (分享在文末)，随时有想法不用打开 Obsidian 也能记录，记录完会自动按时间线罗列在每日日记中，等到第二天早上打开昨天的日记，花一点时间从中捞取有价值的想法整理加工成一个想法素材，卢曼把这个叫永久笔记，但我更喜欢 Andy 的命名：常青笔记（EvergreenNote），在数字时代这意味着这个笔记的内容并不是永恒不变的，随着时间的推移，我可以不断完善这个想法，或者按照原子化的思路重新拆分成不同的想法。</p><h3>双向链接</h3><p>双向链接不是一个新鲜的概念，在学术文献查询时一直都有引证和被引的概念，但过往的笔记应用大多数都是单向链接，双链打开了笔记新的可能性，也让如同卢曼那样复杂的手动链接方式变得简单。</p><p>链接是 Obsidian 的一等公民，是最最重要的功能，因为有双链，当我研究某个主题的时候就可以很快地将笔记库中的相关笔记提取出来，为我所用。相较于卢曼时代完全依靠手工的笔记连接，在计算机的加持下连接变得简单且更加强大。</p><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212160128316.png" alt="Pasted image 20221216004530"/><p>Obsidian 的连接有四种，不仅包括笔记中的链接和反向链接，还可以自动根据笔记标题检索出当前笔记中潜在的链接和提到当前笔记标题但是没有建立链接的笔记，这两种潜在链接的提示降低了人脑主动检索既有笔记进行连接的压力，当然为了实现这点，起好笔记标题在 Obsidian 非常重要。</p><p>好的笔记应该可以惊喜到你，而丰富的链接正是为了帮你找到你曾经知道但现在没想到的想法，连接过去与现在，也是因为丰富的链接，当下记录的想法不会白费，会在未来的某刻再次看见。所谓的惊喜，其实都是时间的馈赠。</p><h3>个性化</h3><p>我比较喜欢 Obsidian 的一点是其提供了丰富的配置以及足够多的插件，笔记本质上是思维的体现，每个人的思维方法是不一样的，使用工具的方式也不尽相同，即使可能有一些思维方法高明一些，但是如果与自己既有思维方式差距太大，那么再高明的思维方法也没办法落地，工具不应要求人去适应它，而应该服务于人。</p><h2>后记</h2><p>这篇分享是我这些天尝试使用卡片笔记法在 Obsidian 上完成的，主要是结合双链笔记的实践，在阅读《卡片笔记写作法》这本书、在浏览 <a href="https://zettelkasten.de/posts/overview/#principles">zettelkasten网站的指南</a> 以及 <a href="https://notes.andymatuschak.org/About_these_notes">Andy关于常青笔记的博文</a> 的过程中写下来的思考笔记的汇总，确实能体验到自下而上的知识管理带来的新力量，在经历笔记方式改变时也有很多困惑和不适应，但通过观察他人的笔记方法可以帮助理解他人的思维过程，用以反思自己思维的局限性，这可能是学习笔记方法与技术的意义所在。</p><h3>福利</h3><p>通过苹果的快捷指令可以在无需打开 Obsidian 的情况下实现灵感笔记快速记录，快捷指令还可以通过 Mac 上的全局快捷键或是 iPhone 上敲击两下手机背面快速打开。</p><p>为了捕捉记录的上下文，下面的速记指令可以自动记录选中的文字或者 Safari 正在访问的链接，还可以通过截屏速记截取屏幕图片并写上批注，记录完自动插入到日记下方。</p><p>macOS 和 iOS 略有不同，插入日记后实现效果如下图，使用的时候需要根据你自身的情况调整下快捷指令中日记文件夹的位置。</p><p><a href="https://www.icloud.com/shortcuts/aaeceb3794d541ccbbd114617bef5ba6">macOS打字速记</a> | <a href="https://www.icloud.com/shortcuts/b8dddc2f03e44b658da1e40768d56329">macOS截屏速记</a> | <a href="https://www.icloud.com/shortcuts/6db03607defc43c7b0bde18e108eb128">iOS打字速记</a>| <a href="https://www.icloud.com/shortcuts/203af4a72212443283beee3697ecb43e">iOS截屏速记</a></p><img src="https://obsidian-1305666858.cos.ap-nanjing.myqcloud.com/202212160128774.png" alt="Group 1"/>]]></content:encoded></item></channel></rss>